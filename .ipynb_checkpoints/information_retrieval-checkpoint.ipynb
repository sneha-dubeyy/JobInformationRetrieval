{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c72b8bb-28a1-4063-adec-b4d0e2d4e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sneha Dubey & Hanzhe Zhang\n",
    "# Dr. Chen\n",
    "# CSCI 185\n",
    "# 20 March 2024\n",
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21572de2-e20f-4f99-8e0c-8b7f898e127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#np.set_printoptions(threshold=sys.maxsize) #OPTIONAL: just to check entirety of prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56020ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your query related to job postings: Nurse Practitioner\n"
     ]
    }
   ],
   "source": [
    "# Ask for user query regarding job listings\n",
    "\n",
    "query = input('Please enter your query related to job postings: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "995985ce-84a0-478b-b6ab-bce5e92d7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalData = pd.read_csv(\"dataset.csv\")\n",
    "#originalData.info()\n",
    "#originalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3e1f8a-29d1-4020-82f4-c28b37ce851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin pre-processing the data (create copy to protect original data)\n",
    "\n",
    "preprocessedData = originalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b09ce1-52b3-4cc9-94c4-6f3fd2318e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns & take care of empty cells\n",
    "\n",
    "preprocessedData = preprocessedData.drop(columns = ['Job Id', 'latitude', 'longitude', 'Contact'], axis = 1)\n",
    "for column in preprocessedData.columns:\n",
    "    preprocessedData[column].fillna('nan', inplace = True)\n",
    "#preprocessedData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f091c3-e0ae-42b4-8763-3c23a3b8844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data (OPTIONAL)\n",
    "\n",
    "#tokenizedData = preprocessedData\n",
    "#for row in range(0,len(tokenizedData.axes[0])):\n",
    "#    for column in tokenizedData:\n",
    "#        tokenizedData.at[row, column] = str(tokenizedData.at[row, column])\n",
    "\n",
    "#for row in range(0,len(tokenizedData.axes[0])):\n",
    "#    for column in tokenizedData:\n",
    "#        tokenizedData.at[row, column] = word_tokenize(tokenizedData.at[row, column])\n",
    "#        print(data)\n",
    "\n",
    "#tokenizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b44e767b-e8af-4886-9317-19b9d8d51cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words (OPTIONAL)\n",
    "\n",
    "#stopWords = set(stopwords.words('english'))\n",
    "#punctuations = set(string.punctuation)\n",
    "#for row in range(0,len(tokenizedData.axes[0])):\n",
    "#    for column in tokenizedData:\n",
    "#        assessedList = []\n",
    "#        for w in tokenizedData.at[row, column]:\n",
    "#                if w not in stopWords and w not in punctuations:\n",
    "#                    assessedList.append(w)\n",
    "#        tokenizedData.at[row, column] = assessedList\n",
    "\n",
    "#tokenizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca278a7-e4ad-4ec3-99ba-8798aa93bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginning Vector Space Model\n",
    "\n",
    "# Moving all documents to be individual lists in a larger 'documents' list for ease\n",
    "documents = []\n",
    "for row in range(0,len(preprocessedData.axes[0])): # use tokenizedData if data was tokenized\n",
    "    currDoc = \"\"\n",
    "    for column in preprocessedData:\n",
    "        currDoc += \" \" + str(preprocessedData.at[row, column])\n",
    "    documents.append(currDoc)\n",
    "documents.append(query)\n",
    "#print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62852de3-9ebd-4f4b-bd64-3682c97ce6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab words:  ['001' '002' '008' ... 'zoning' 'zts' 'zuckerberg']\n",
      "TF-IDF Matrix: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_martix = tfidf_matrix.toarray()\n",
    "print('Vocab words: ', feature_names)\n",
    "print('TF-IDF Matrix: \\n', tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfcdaeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cosine similarities\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "#print('cosine similarities: ', cosine_similarities)\n",
    "\n",
    "num_rows, num_columns = cosine_similarities.shape\n",
    "ranked_order = np.argsort(-cosine_similarities[:num_rows-1, num_columns-1], axis = 0)\n",
    "#print('Ranked order of documents: ', ranked_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d9e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job posting most relevant to your query (Nurse Practitioner) is Job ID:  2006780000000000.0 \n",
      "\n",
      "Information about this position: \n",
      "\n",
      "Experience :  0 to 13 Years \n",
      "\n",
      "Qualifications :  BA \n",
      "\n",
      "Salary Range :  $61K-$99K \n",
      "\n",
      "location :  Kingston \n",
      "\n",
      "Country :  Jamaica \n",
      "\n",
      "latitude :  18.1096 \n",
      "\n",
      "longitude :  -77.2975 \n",
      "\n",
      "Work Type :  Temporary \n",
      "\n",
      "Company Size :  69236 \n",
      "\n",
      "Job Posting Date :  5/27/2023 \n",
      "\n",
      "Preference :  Both \n",
      "\n",
      "Contact Person :  Anthony Thornton \n",
      "\n",
      "Contact :  402-317-0630x3450 \n",
      "\n",
      "Job Title :  Nurse Practitioner \n",
      "\n",
      "Role :  Primary Care Nurse Practitioner \n",
      "\n",
      "Job Portal :  CareerBuilder \n",
      "\n",
      "Job Description :  Primary Care Nurse Practitioners provide essential healthcare services, diagnosing and treating common medical conditions, and offering preventive care to patients. \n",
      "\n",
      "Benefits :  {'Childcare Assistance, Paid Time Off (PTO), Relocation Assistance, Flexible Work Arrangements, Professional Development'} \n",
      "\n",
      "skills :  Nursing care Patient assessment Health promotion Medication administration Electronic health records (EHR) \n",
      "\n",
      "Responsibilities :  Provide comprehensive primary healthcare services, including assessments, diagnoses, and treatments. Educate patients on health management and prevention. Prescribe medications and develop care plans. \n",
      "\n",
      "Company :  Xiaomi Corporation \n",
      "\n",
      "Company Profile :  {\"Sector\":\"Technology and Electronics\",\"Industry\":\"Technology & Electronics\",\"City\":\"Beijing\",\"State\":\"N/A\",\"Zip\":\"N/A\",\"Website\":\"https://www.mi.com/en/\",\"Ticker\":\"1810.HK\",\"CEO\":\"Lei Jun\"} \n",
      "\n",
      "The next two most relevant jobs' IDs are:  90206300000000.0  and  107968000000000.0  respectively\n"
     ]
    }
   ],
   "source": [
    "# Print job listings most relevant to the user's query\n",
    "print('The job posting most relevant to your query', '(' + query + ')', 'is Job ID: ', originalData['Job Id'].loc[originalData.index[ranked_order[0]]], '\\n')\n",
    "print('Information about this position: \\n')\n",
    "for column in originalData:\n",
    "    if column == 'Job Id':\n",
    "        continue\n",
    "    print(column, ': ', originalData[column].loc[originalData.index[ranked_order[0]]], '\\n')\n",
    "    \n",
    "print('The next two most relevant jobs\\' IDs are: ', originalData['Job Id'].loc[originalData.index[ranked_order[1]]],' and ', originalData['Job Id'].loc[originalData.index[ranked_order[2]]],' respectively')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cce231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of information retrieval!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
